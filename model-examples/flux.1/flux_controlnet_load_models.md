# æ¨¡å‹åŠ è½½ã€controlnet åˆå§‹åŒ–ä¸æ¨¡å—ç²¾åº¦è®¾ç½®

å»¶ç»­ FLUX.1 lora dreambooth å¾®è°ƒ [æ¨¡å‹åŠ è½½ã€LoRAå±‚åˆå§‹åŒ–ä¸æ¨¡å—ç²¾åº¦è®¾ç½®](flux_lora_load_models.md) ä¸­çš„ä»‹ç»ï¼Œæœ¬æ–‡ç»§ç»­å¯¹ FLUX.1 controlnet å¾®è°ƒä½œå¯¹åº”çš„ç®€å•çš„å®è·µåˆ†äº«ã€‚ä¸Šç¯‡æåˆ°çš„ä¸€äº›ç‚¹å¯èƒ½ä¸åœ¨æ­¤é‡å¤å±•å¼€ï¼Œå»ºè®®æŒ‰é¡ºåºé˜…è¯»ã€‚


## æ¨¡å‹åŠ è½½ä¸ controlnet åˆå§‹åŒ–

FLUX.1 controlnet å¾®è°ƒå¯¹æ¯” lora å¾®è°ƒï¼Œéœ€è¦é¢å¤–å®šä¹‰ flux_controlnet æ¨¡å‹ã€‚å…¶ä»–éƒ¨åˆ†ä¸ flux lora å¾®è°ƒçš„æ¨¡å‹åŠ è½½ä¸€è‡´ï¼š

```python
from transformers import AutoTokenizer, PretrainedConfig
from mindone.transformers import CLIPTextModel, T5EncoderModel
from mindone.diffusers import AutoencoderKL, FlowMatchEulerDiscreteScheduler, FluxTransformer2DModel

# Load the tokenizers
tokenizer_one = AutoTokenizer.from_pretrained(
    args.pretrained_model_name_or_path,
    subfolder="tokenizer",
    revision=args.revision,
)
# load t5 tokenizer
tokenizer_two = AutoTokenizer.from_pretrained(
    args.pretrained_model_name_or_path,
    subfolder="tokenizer_2",
    revision=args.revision,
)
# load clip text encoder
text_encoder_one = CLIPTextModel.from_pretrained(
    args.pretrained_model_name_or_path, subfolder="text_encoder", revision=args.revision, variant=args.variant
)
# load t5 text encoder
text_encoder_two = T5EncoderModel.from_pretrained(
    args.pretrained_model_name_or_path, subfolder="text_encoder_2", revision=args.revision, variant=args.variant
)

vae = AutoencoderKL.from_pretrained(
    args.pretrained_model_name_or_path,
    subfolder="vae",
    revision=args.revision,
    variant=args.variant,
)
flux_transformer = FluxTransformer2DModel.from_pretrained(
    args.pretrained_model_name_or_path,
    subfolder="transformer",
    revision=args.revision,
    variant=args.variant,
)

noise_scheduler = FlowMatchEulerDiscreteScheduler.from_pretrained(
    args.pretrained_model_name_or_path,
    subfolder="scheduler",
)
```
`FluxControlNetModel` æ¨¡å‹åœ¨ mindONE.diffusers 0.30 ç‰ˆæœ¬æ”¯æŒã€‚å®šä¹‰æ—¶å¯ä»¥é€šè¿‡ `from_pretrained` ä»ç¤¾åŒºä¸ŠåŠ è½½è®­ç»ƒå¥½çš„ controlnet æ¨¡å‹ï¼Œä¹Ÿå¯ä»¥ç›´æ¥æŒ‰ç…§è‡ªå·±éœ€è¦çš„é€šè¿‡ `from_transformer` æ¥å£æ ¹æ®å®šä¹‰å¥½çš„ flux_transformer åˆå§‹åŒ–ä¸€ä¸ªå…¨æ–°çš„ã€‚

```python
if args.controlnet_model_name_or_path:
    logger.info("Loading existing controlnet weights")
    flux_controlnet = FluxControlNetModel.from_pretrained(args.controlnet_model_name_or_path)
else:
    logger.info("Initializing controlnet weights from transformer")
    # we can define the num_layers, num_single_layers,
    flux_controlnet = FluxControlNetModel.from_transformer(
        flux_transformer,
        attention_head_dim=flux_transformer.config["attention_head_dim"],
        num_attention_heads=flux_transformer.config["num_attention_heads"],
        num_layers=args.num_double_layers,
        num_single_layers=args.num_single_layers,
    )

```

åŠ è½½åï¼Œæˆ‘ä»¬å¯¹ä¸éœ€è¦è®­ç»ƒçš„æ¨¡å‹è¿›è¡Œå‚æ•°å†»ç»“ï¼Œè®¾ `requires_grad = False`ã€‚è¿™é‡Œåªæœ‰ `flux_controlnet` ä¸éœ€è¦å¤„ç†ï¼Œé»˜è®¤æ˜¯ `True`ã€‚


```python
# We only train the flux_controlnet
from mindspore import nn
def freeze_params(m: nn.Cell):
    for p in m.get_parameters():
        p.requires_grad = False

freeze_params(vae)
freeze_params(flux_transformer)
freeze_params(text_encoder_one)
freeze_params(text_encoder_two)
```

## æ¨¡å—ç²¾åº¦è®¾ç½®

ç²¾åº¦è®¾ç½®å¯¹æˆ‘ä»¬çš„å¾®è°ƒç»“æœæ¯”è¾ƒé‡è¦ï¼Œè¿™éƒ¨åˆ†ä»‹ç»ä¸€ä¸‹ flux controlnet å¾®è°ƒå®è·µæ—¶çš„å„ä¸ªæ¨¡å—çš„å‚æ•°ç²¾åº¦ã€è¿è¡Œç²¾åº¦çš„è®¾ç½®ã€‚å‡è®¾æˆ‘ä»¬åªå¾®è°ƒ transformers çš„éƒ¨åˆ†ã€‚é¦–å…ˆçœ‹ä¸€ä¸‹ flux_transformer å‚æ•°é‡å¤§çº¦ä¸º 11.9Bï¼Œä¸è¿‡è¿™éƒ¨åˆ†åªå‚ä¸å‰å‘ã€‚å‚ä¸è®­ç»ƒçš„ flux_controlnet å‚æ•°é‡å¤§çº¦ 1.44Bã€‚æ¯” LoRA å¾®è°ƒè¿˜æ˜¯æ¥è¯´æ˜¯â€œé‡é‡çº§â€è®­ç»ƒã€‚è€ƒè™‘åˆ°è®­ç»ƒæ€§èƒ½å’Œæ˜¾å­˜é—®é¢˜ï¼Œæˆ‘ä»¬æš‚æ—¶æŠŠä¸å‚ä¸è®­ç»ƒçš„å‚æ•°ç²¾åº¦è®¾ä¸º `bf16`ã€‚

```python
# æŸ¥çœ‹å‚æ•°é‡çš„æ ·ä¾‹ä»£ç 
all_params = sum(p.numel() for p in flux_transformer.get_parameters())
trainable_params = sum(p.numel() for p in flux_controlnet.trainable_params())
```

vae, flux_transformer ä¸å‚ä¸è®­ç»ƒçš„æ¨¡å—ï¼Œåªå‚ä¸å‰å‘è¿ç®—ï¼Œæƒé‡æ— éœ€ä¿æŒå…¨ç²¾åº¦ã€‚`flux_controlnet` ä½¿ç”¨ to_float() å®ç°æ‰‹åŠ¨æ··ç²¾ï¼Œä½¿ç”¨åŠç²¾åº¦è®¡ç®—ï¼Œå…¶å‚æ•°çš„ç²¾åº¦åˆ™å­˜ä¸ºå…¨ç²¾åº¦ `fp32`ï¼Œå› ä¸ºæˆ‘ä»¬ä½¿ç”¨ mindspore æ¡†æ¶çš„ä¼˜åŒ–å™¨ï¼Œæ¯”å¦‚ `nn.AdamWeightDecay`, å½“å‰æ˜¯æŒ‰ç…§å‚æ•°çš„ç²¾åº¦åšæ¢¯åº¦æ›´æ–°çš„ï¼Œè€Œä¸ä¼šåœ¨åå‘æ›´æ–°æƒé‡æ—¶è‡ªåŠ¨ upcastã€‚å‡å¦‚è®­ç»ƒå‚æ•°ä¹Ÿè®¾ç½®æˆåŠç²¾åº¦ï¼Œå˜æˆå®Œå…¨çš„åŠç²¾åº¦è®­ç»ƒï¼Œåœ¨æ¢¯åº¦æ›´æ–°æ—¶å¯èƒ½ä¼šå¯¼è‡´æº¢å‡ºï¼Œæ— æ³•æ­£å¸¸è®­ç»ƒã€‚

ç›¸å…³ä»£ç ç‰‡æ®µä»¥ä¾›å‚è€ƒï¼š

```python
import mindspore as ms
# For mixed precision training we cast the text_encoder and vae weights to half-precision
# as these models are only used for inference, keeping weights in full precision is not required.
weight_dtype = ms.float32
if args.mixed_precision == "fp16":
    weight_dtype = ms.float16
elif args.mixed_precision == "bf16":
    weight_dtype = ms.bfloat16

vae.to(dtype=weight_dtype)
flux_transformer.to(dtype=weight_dtype)

flux_controlnet.to_float(weight_dtype)
```

è¿™é‡Œæˆ‘ä»¬æš‚æ—¶æ²¡æœ‰å¤„ç† text encodersï¼Œhuggingface diffusers ç»™å‡ºçš„è®­ç»ƒæ ·ä¾‹æ˜¯ clip å’Œ T5 ä»¥å…¨ç²¾åº¦ï¼Œè®­ç»ƒå‰é€šè¿‡ `compute_embeddings` è®¡ç®—ååˆ é™¤ä»¥é‡Šæ”¾å†…å­˜ã€‚

å½“å‰ `args.mixed_precision = bf16` ä¸ºä¾‹ï¼Œé¢„æœŸå„æ¨¡å—çš„å‚æ•°ç²¾åº¦ã€è®¡ç®—ç²¾åº¦ä¸ºï¼š

| precision   | vae  | textencoders | flux_transformer | flux_controlnet |
| :---------: | :--: | :----------: | :----------: | :---------: |
| parameters  | bf16 | fp32         | bf16         | fp32        |
| computation | bf16 | fp32         | bf16         | bf16        |


ä½†æ˜¯å‚è€ƒæ–‡æ¡£ [Run ğŸ¤—Diffusers-Style Training on MindSpore](https://gist.github.com/townwish4git/3a181a1884747dfbbe4b31107ec02166)æ‰€è¯´ï¼Œç›®å‰MindSporeå†…å­˜æ± æ²¡æœ‰æ¸…ç©ºå†…å­˜ç¢ç‰‡çš„åŠŸèƒ½ï¼Œtext encoders è½½å…¥æ—¶åˆ†é…äº†çš„æ˜¾å­˜ï¼Œdel ä¹‹åå¹¶æ²¡æœ‰çœŸæ­£é‡Šæ”¾ã€‚ä¸ºäº†æŠ ç‚¹æ˜¾å­˜ï¼Œæˆ–è®¸å¯ä»¥å°è¯•è®¡ç®—å text encoders çš„`compute_embeddings` å®Œæˆè®¡ç®—åï¼Œå…ˆè½¬æˆ bf16ï¼Œç„¶åå†åˆ é™¤ï¼ˆåæ­£å¯èƒ½æ˜¯å‡æ€§åˆ é™¤ï¼‰ã€‚

```python
# æ–‡æœ¬è®¡ç®—
... = compute_embeddings(text_encoder_one, text_encoder_two)

# ç®—å¥½åå¯ä»¥åˆ é™¤äº†ï¼Œé˜²æ­¢å‡æ€§åˆ é™¤ï¼Œåˆ é™¤å‰å…ˆè½¬ä¸€ä¸‹åŠç²¾åº¦
text_encoder_one.to(dtype=weight_dtype)
text_encoder_two.to(dtype=weight_dtype)
del text_encoder_one, text_encoder_two
```

ä¸Šé¢çš„ä»£ç ç‰‡æ®µå¯è¯»æ€§å·®ï¼Œå®¹æ˜“è®©äººç–‘æƒ‘ï¼Œæ˜¾å­˜å¤Ÿçš„è¯å¯ä»¥ä¸éœ€è¦è¿™æ ·å¤„ç†ã€‚åˆæˆ–è€…æˆ‘ä»¬ç›´æ¥ä½¿ç”¨ `bf16` è®¡ç®— text embeddingï¼Œè®­ç»ƒç²¾åº¦å¦‚æœæ²¡é—®é¢˜ä¹Ÿokã€‚

| precision   | vae  | textencoders | flux_transformer | flux_controlnet |
| :---------: | :--: | :----------: | :----------: | :---------: |
| parameters  | bf16 | bf16         | bf16         | fp32        |
| computation | bf16 | bf16         | bf16         | bf16        |

```python
import mindspore as ms
# For mixed precision training we cast the text_encoder and vae weights to half-precision
# as these models are only used for inference, keeping weights in full precision is not required.
weight_dtype = ms.float32
if args.mixed_precision == "fp16":
    weight_dtype = ms.float16
elif args.mixed_precision == "bf16":
    weight_dtype = ms.bfloat16

vae.to(dtype=weight_dtype)
flux_transformer.to(dtype=weight_dtype)
text_encoder_one.to(dtype=weight_dtype)
text_encoder_two.to(dtype=weight_dtype)
flux_controlnet.to_float(weight_dtype)
```
