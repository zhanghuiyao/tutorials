{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "620b1bb9-d188-4916-8a88-392b301e78dd",
   "metadata": {},
   "source": [
    "## mindspore.ops.cummax(input, axis) -〉 Tensor\n",
    "- 输入：\n",
    "    * input必须为mindspore的tensor。\n",
    "    * axis必须为int类型。\n",
    "- 返回：元组类型，包含两个tensor。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "518c829d-80a5-4d98-b90c-09635ae35665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mindspore output ->\n",
      " (Tensor(shape=[4, 4], dtype=Int64, value=\n",
      "[[ 3,  4,  6, 10],\n",
      " [ 3,  6,  7, 10],\n",
      " [ 4,  6,  8, 10],\n",
      " [ 4,  6,  8, 10]]), Tensor(shape=[4, 4], dtype=Int64, value=\n",
      "[[0, 0, 0, 0],\n",
      " [0, 1, 1, 0],\n",
      " [2, 1, 2, 0],\n",
      " [2, 1, 2, 0]]))\n",
      "\n",
      "\n",
      "torch     output ->\n",
      " torch.return_types.cummax(\n",
      "values=tensor([[ 3,  4,  6, 10],\n",
      "        [ 3,  6,  7, 10],\n",
      "        [ 4,  6,  8, 10],\n",
      "        [ 4,  6,  8, 10]]),\n",
      "indices=tensor([[0, 0, 0, 0],\n",
      "        [0, 1, 1, 0],\n",
      "        [2, 1, 2, 0],\n",
      "        [2, 1, 2, 0]]))\n",
      "\n",
      "\n",
      "jax       output ->\n",
      " [[ 3  4  6 10]\n",
      " [ 3  6  7 10]\n",
      " [ 4  6  8 10]\n",
      " [ 4  6  8 10]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mindspore as ms\n",
    "import torch\n",
    "import jax.lax as jlx\n",
    "\n",
    "input = np.array([[3, 4, 6, 10], [1, 6, 7, 9], [4, 3, 8, 7], [1, 3, 7, 9]])\n",
    "\n",
    "y1 = ms.ops.cummax(ms.tensor(input), axis = 0)\n",
    "y2 = torch.cummax(torch.tensor(input), dim = 0)\n",
    "y3 = jlx.cummax(input, axis = 0)\n",
    "print ('mindspore output ->\\n',y1)\n",
    "print('\\n')\n",
    "print ('torch     output ->\\n',y2)\n",
    "print('\\n')\n",
    "print ('jax       output ->\\n',y3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00564cac-e16c-4328-a4a4-a16a61f5053a",
   "metadata": {},
   "source": [
    "1、ms的输出value在最后面，建议提前。  \n",
    "2、jax的输出为array, 不会输出最大值的索引。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba60e6bf-fa84-460e-9c55-edc183841548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch     output ->\n",
      " (tensor([[ 3,  4,  6, 10],\n",
      "        [ 3,  6,  7, 10],\n",
      "        [ 4,  6,  8, 10],\n",
      "        [ 4,  6,  8, 10]]), tensor([[0, 0, 0, 0],\n",
      "        [0, 1, 1, 0],\n",
      "        [2, 1, 2, 0],\n",
      "        [2, 1, 2, 0]]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wy/5yzfdb6x7pvfxh89zcmf_w780000gn/T/ipykernel_65183/2453569664.py:3: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [4, 4]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at /private/var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_68u_j54pu8/croot/pytorch-select_1717607460029/work/aten/src/ATen/native/Resize.cpp:35.)\n",
      "  torch.cummax(torch.tensor(input), dim = 0, out = out2)\n"
     ]
    }
   ],
   "source": [
    "out2 = (torch.tensor([0]),torch.tensor([0]))\n",
    "\n",
    "torch.cummax(torch.tensor(input), dim = 0, out = out2)\n",
    "print ('torch     output ->\\n',out2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abe5364-1176-4504-b6a3-27776a962619",
   "metadata": {},
   "source": [
    "torch还提供了出参的方式，ms未支持。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fcbe1fa-7af2-4f85-9c27-c318cb2e7017",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Failed calling Cummax with \"Cummax(axis=int)(input=<class 'numpy.ndarray'>)\".\nThe valid calling should be: \n\"Cummax(axis=<int>)(input=<Tensor>)\".\n\n----------------------------------------------------\n- C++ Call Stack: (For framework developers)\n----------------------------------------------------\nmindspore/ccsrc/pipeline/pynative/pynative_utils.cc:1294 PrintTypeCastError\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y1 \u001b[38;5;241m=\u001b[39m \u001b[43mms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcummax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/auto_generate/gen_ops_def.py:1754\u001b[0m, in \u001b[0;36mcummax\u001b[0;34m(input, axis)\u001b[0m\n\u001b[1;32m   1706\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcummax\u001b[39m(\u001b[38;5;28minput\u001b[39m, axis):\n\u001b[1;32m   1707\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1708\u001b[0m \u001b[38;5;124;03m    Returns a tuple (values,indices) where 'values' is the cumulative maximum value of input Tensor `input`\u001b[39;00m\n\u001b[1;32m   1709\u001b[0m \u001b[38;5;124;03m    along the dimension `axis`, and `indices` is the index location of each maximum value.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1752\u001b[0m \u001b[38;5;124;03m         [2 1 2 0]]\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1754\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcummax_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/auto_generate/pyboost_inner_prim.py:188\u001b[0m, in \u001b[0;36m_PyboostCummaxPrim.__call__\u001b[0;34m(self, input, axis)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, axis):\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _convert_stub(\u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Failed calling Cummax with \"Cummax(axis=int)(input=<class 'numpy.ndarray'>)\".\nThe valid calling should be: \n\"Cummax(axis=<int>)(input=<Tensor>)\".\n\n----------------------------------------------------\n- C++ Call Stack: (For framework developers)\n----------------------------------------------------\nmindspore/ccsrc/pipeline/pynative/pynative_utils.cc:1294 PrintTypeCastError\n"
     ]
    }
   ],
   "source": [
    "y1 = ms.ops.cummax(input, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1050b2d7-b6e4-4cce-90ed-9797c0dba5e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cummax() received an invalid combination of arguments - got (numpy.ndarray, dim=int), but expected one of:\n * (Tensor input, int dim, *, tuple of Tensors out)\n * (Tensor input, name dim, *, tuple of Tensors out)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y2 \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcummax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: cummax() received an invalid combination of arguments - got (numpy.ndarray, dim=int), but expected one of:\n * (Tensor input, int dim, *, tuple of Tensors out)\n * (Tensor input, name dim, *, tuple of Tensors out)\n"
     ]
    }
   ],
   "source": [
    "y2 = torch.cummax(input, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1701d368-1e09-40f9-833e-122dcf6446d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot interpret 'torch.int64' as a data type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y3 \u001b[38;5;241m=\u001b[39m \u001b[43mjlx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcummax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mindspore/lib/python3.9/site-packages/jax/_src/lax/control_flow/loops.py:2295\u001b[0m, in \u001b[0;36mcummax\u001b[0;34m(operand, axis, reverse)\u001b[0m\n\u001b[1;32m   2293\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcummax\u001b[39m(operand: Array, axis: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, reverse: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Array:\n\u001b[1;32m   2294\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Computes a cumulative maximum along `axis`.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2295\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcummax_p\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreverse\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mindspore/lib/python3.9/site-packages/jax/_src/core.py:416\u001b[0m, in \u001b[0;36mPrimitive.bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[1;32m    414\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m config\u001b[38;5;241m.\u001b[39menable_checks\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    415\u001b[0m           \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(arg, Tracer) \u001b[38;5;129;01mor\u001b[39;00m valid_jaxtype(arg) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)), args\n\u001b[0;32m--> 416\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfind_top_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mindspore/lib/python3.9/site-packages/jax/_src/core.py:420\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[1;32m    419\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m pop_level(trace\u001b[38;5;241m.\u001b[39mlevel):\n\u001b[0;32m--> 420\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_raise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    421\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(full_lower, out) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultiple_results \u001b[38;5;28;01melse\u001b[39;00m full_lower(out)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mindspore/lib/python3.9/site-packages/jax/_src/core.py:921\u001b[0m, in \u001b[0;36mEvalTrace.process_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    919\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m call_impl_with_key_reuse_checks(primitive, primitive\u001b[38;5;241m.\u001b[39mimpl, \u001b[38;5;241m*\u001b[39mtracers, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 921\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprimitive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtracers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mindspore/lib/python3.9/site-packages/jax/_src/dispatch.py:87\u001b[0m, in \u001b[0;36mapply_primitive\u001b[0;34m(prim, *args, **params)\u001b[0m\n\u001b[1;32m     85\u001b[0m prev \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mjax_jit\u001b[38;5;241m.\u001b[39mswap_thread_local_state_disable_jit(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 87\u001b[0m   outs \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     89\u001b[0m   lib\u001b[38;5;241m.\u001b[39mjax_jit\u001b[38;5;241m.\u001b[39mswap_thread_local_state_disable_jit(prev)\n",
      "    \u001b[0;31m[... skipping hidden 8 frame]\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mindspore/lib/python3.9/site-packages/jax/_src/dtypes.py:347\u001b[0m, in \u001b[0;36missubdtype\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns True if first argument is a typecode lower/equal in type hierarchy.\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \n\u001b[1;32m    332\u001b[0m \u001b[38;5;124;03mThis is like :func:`numpy.issubdtype`, but can handle dtype extensions such as\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03m:obj:`jax.dtypes.bfloat16` and `jax.dtypes.prng_key`.\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;66;03m# Main departures from np.issubdtype are:\u001b[39;00m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;66;03m# - \"extended\" dtypes (like prng key types) are not normal numpy dtypes, so we\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;66;03m#   need to handle them specifically. However, their scalar types do conform to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# unhashable (e.g. custom objects with a dtype attribute). The following check is\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# fast and covers the majority of calls to this function within JAX library code.\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _issubdtype_cached(\n\u001b[0;32m--> 347\u001b[0m   a \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, (\u001b[38;5;28mtype\u001b[39m, np\u001b[38;5;241m.\u001b[39mdtype, ExtendedDType)) \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    348\u001b[0m   b \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, (\u001b[38;5;28mtype\u001b[39m, np\u001b[38;5;241m.\u001b[39mdtype, ExtendedDType)) \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mdtype(b),  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    349\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot interpret 'torch.int64' as a data type"
     ]
    }
   ],
   "source": [
    "y3 = jlx.cummax(torch.tensor(input), axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59517714-1ef1-43d2-ac0e-7b84d4ab1c65",
   "metadata": {},
   "source": [
    "当输入类型不正确时，报错信息torch最简洁明确。建议ms优化。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
